ğŸ“‚ Project Structure
orianna-assistant/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               # Entry point, initializes tools and agent
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ email_tool.py      # Gmail API Integration
â”‚   â”‚   â”œâ”€â”€ weather_tool.py    # Weather API Fetcher
â”‚   â”‚   â”œâ”€â”€ calendar_tool.py   # Google Calendar API
â”‚   â”‚   â”œâ”€â”€ llm_tool.py        # Local LLM Integration (Mistral 7B)
â”‚   â”œâ”€â”€ database.py            # PostgreSQL connection (pgvector for memory)
â”‚   â”œâ”€â”€ memory.py              # Handles agent memory (embedding storage)
â”‚â”€â”€ models/
â”‚   â”œâ”€â”€ embeddings.py          # Converts text to embeddings
â”‚â”€â”€ config.py                  # Configurations (API keys, model paths)
â”‚â”€â”€ requirements.txt           # Dependencies
â”‚â”€â”€ setup.sh                   # Initial setup script
â”‚â”€â”€ README.md                  # Project Docs

ğŸ“Œ Database Schema (PostgreSQL + pgvector)
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE memory (
    id SERIAL PRIMARY KEY,
    user_input TEXT NOT NULL,
    ai_response TEXT NOT NULL,
    embedding VECTOR(1536) NOT NULL, -- Adjust dimensions based on model
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

ğŸ”¥ Core Files & Code

1ï¸âƒ£ database.py - PostgreSQL Connection
import psycopg2
from psycopg2.extras import RealDictCursor
import os

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/orianna")

def get_db_connection():
    return psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)

def store_memory(user_input, ai_response, embedding):
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO memory (user_input, ai_response, embedding)
        VALUES (%s, %s, %s);
    """, (user_input, ai_response, embedding))
    conn.commit()
    cur.close()
    conn.close()

2ï¸âƒ£ llm_tool.py - Local LLM Integration (Mistral 7B)
from llama_cpp import Llama
import os

MODEL_PATH = os.getenv("MODEL_PATH", "models/mistral-7b-instruct.Q4_K_M.gguf")

# Load Mistral 7B
llm = Llama(model_path=MODEL_PATH)

def ask_llm(prompt):
    response = llm(prompt)
    return response["choices"][0]["text"].strip()

3ï¸âƒ£ embeddings.py - Generate Embeddings
from sentence_transformers import SentenceTransformer

# Load embedding model
embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Efficient for local use

def get_embedding(text):
    return embedder.encode(text).tolist()

4ï¸âƒ£ email_tool.py - Fetch Gmail Emails
from googleapiclient.discovery import build
from google.oauth2 import service_account
import os

SCOPES = ["https://www.googleapis.com/auth/gmail.readonly"]
SERVICE_ACCOUNT_FILE = os.getenv("GMAIL_CREDENTIALS", "config/gmail_credentials.json")

def get_gmail_service():
    creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
    return build("gmail", "v1", credentials=creds)

def fetch_recent_emails():
    service = get_gmail_service()
    results = service.users().messages().list(userId="me", maxResults=5).execute()
    messages = results.get("messages", [])

    email_data = []
    for msg in messages:
        msg_detail = service.users().messages().get(userId="me", id=msg["id"]).execute()
        headers = msg_detail.get("payload", {}).get("headers", [])
        
        subject = next((h["value"] for h in headers if h["name"] == "Subject"), "No Subject")
        sender = next((h["value"] for h in headers if h["name"] == "From"), "Unknown Sender")

        email_data.append({"subject": subject, "sender": sender})

    return email_data

5ï¸âƒ£ memory.py - Store and Retrieve Memory
from database import store_memory, get_db_connection
from embeddings import get_embedding
import psycopg2

def store_conversation(user_input, ai_response):
    embedding = get_embedding(user_input)
    store_memory(user_input, ai_response, embedding)

def retrieve_memory(query):
    conn = get_db_connection()
    cur = conn.cursor()
    query_embedding = get_embedding(query)

    cur.execute("""
        SELECT user_input, ai_response FROM memory
        ORDER BY embedding <-> %s LIMIT 3;
    """, (query_embedding,))
    
    memories = cur.fetchall()
    cur.close()
    conn.close()

    return memories

6ï¸âƒ£ main.py - Main Assistant Logic
from llm_tool import ask_llm
from email_tool import fetch_recent_emails
from memory import store_conversation, retrieve_memory

def handle_input(user_input):
    # Retrieve memory context
    past_memories = retrieve_memory(user_input)
    memory_context = "\n".join([f"User: {m['user_input']}\norianna: {m['ai_response']}" for m in past_memories])

    # Construct prompt
    prompt = f"Past Context:\n{memory_context}\n\nUser: {user_input}\norianna:"
    response = ask_llm(prompt)

    # Store new interaction
    store_conversation(user_input, response)

    return response

if __name__ == "__main__":
    while True:
        user_input = input("You: ")
        if user_input.lower() == "exit":
            break
        
        if "emails" in user_input:
            emails = fetch_recent_emails()
            for email in emails:
                print(f"ğŸ“§ {email['sender']}: {email['subject']}")
        else:
            response = handle_input(user_input)
            print(f"orianna: {response}")

ğŸš€ Next Steps (Phase 2)
1ï¸âƒ£ Enhancing Learning Capabilities
    Store more structured memory (e.g., user preferences, task history).
    Improve prompt engineering to make the LLM more context-aware.
2ï¸âƒ£ Speech Recognition & Response
    Voice Input: Use whisper.cpp for local speech recognition.
    Text-to-Speech: Use piper-tts for realistic voice output.
3ï¸âƒ£ Automate Personal Tasks
    Auto-Read Emails & Summarize (daily summaries).
    Intelligent Scheduling (pull tasks from calendar).
    Expense/Budget Tracker (analyze transactions).
ğŸ’¡ Summary
âœ”ï¸ LLM (Mistral 7B) is now integrated to respond contextually.
âœ”ï¸ PostgreSQL + pgvector is storing conversation history for learning.
âœ”ï¸ Emails can be fetched via Gmail API when requested.
âœ”ï¸ Simple CLI interaction for now (UI coming later).

ğŸš€ What do you want to tackle next?
1ï¸âƒ£ Fine-tuning the LLM on personal data?
2ï¸âƒ£ Voice integration (speech-to-text & TTS)?
3ï¸âƒ£ More advanced tools (budget tracker, home automation, etc.)?